# CS 1440 Project 4.0: Refactoring - Instructions

Previous Semester Statistics     | Fall 2023 | Spring 2024 | Fall 2024  
--------------------------------:|:---------:|:------------|:---------- 
Average Hours Spent              | 13.61     | 12.68       | 12.8       
Standard Deviation Hours         | 5.462     | 6.017       | 5.1        
% students thought this was Easy | 6.5%      | 2.4%        | 1.4%       
... Medium                       | 38.7%     | 26.5%       | 32.4%      
... Hard                         | 44.1%     | 37.3%       | 38.0%      
... Too Hard/Did not complete    | 9.7%      | 33.7%       | 28.2%      


**Grace Points**: If these tags are pushed to GitLab before 11:59 PM on the Monday before the due date, you will get up to **5 grace points** per tag:

0.  `4.0-analyzed`
1.  `4.0-designed`

To be eligible for grace points these tags must be on **separate commits**; they cannot be together.


*   [AI Tools / External Resources Policy](#ai-tools-external-resources-policy)
*   [How to Do This Project](#how-to-do-this-project)
    *   [Phase 0: Requirements Analysis](#phase-0-requirements-analysis-tag-name-40-analyzed)
    *   [Phase 1: Design](#phase-1-design-tag-name-40-designed)
    *   [Phase 2: Implementation](#phase-2-implementation-tag-name-40-implemented)
    *   [Phase 3: Testing and Debugging](#phase-3-testing-and-debugging-tag-name-40-tested)
    *   [Phase 4: Deployment](#phase-4-deployment-tag-name-40-deployed)
    *   [Phase 5: Maintenance](#phase-5-maintenance-tag-name-40-finished)
*   [What We Look for When Grading](#what-we-look-for-when-grading)



## AI Tools / External Resources Policy

I will not accept code or documentation that is not 100% your own creation.

You may use AI and external resources in ways that assist your understanding without replacing your effort or responsibility to learn.

Acceptable uses include:

*   Analyzing project instructions.
*   Understanding why and how starter code works.
*   Brainstorming ideas for a prototype.
*   Researching and explaining error messages.
*   Proofreading your documentation.

Unacceptable uses include:

*   Generating code, including unit tests.
*   Debugging your code or suggesting fixes.
*   Writing parts of your software plan or any other deliverable.

If you're stuck, ask for help before resorting to shortcuts or risking a violation.



## How to Do This Project

*   Your grade on this project depends upon how well you follow the SDP.  You demonstrate this by following instructions, writing clear documentation, and by *tagging* commits.
    *   Incorrectly spelled/capitalized tags are ignored.
    *   **If you tag a wrong commit**, or **incorrectly spell a tag** refer to `Using_Git/Intermediate_Git.md` in the lecture notes for instructions.


### Phase 0: Requirements Analysis (tag name `4.0-analyzed`)
*(20% of your effort)*

**Important - do not change any code in this phase**

0.  Read the [Project Requirements](./4.0-Project_Requirements.md) to orient yourself with the project
1.  Read and run the starter code to learn how it works
    *   You may use AI tools such as ChatGPT or GitHub Copilot to assist you in understanding the starter code
        *   If you do this, explain how you used it in your Software Development Plan
    *   Not all of the fractal files under the `data/` directory produce interesting images; how well they work depends on whether they match the algorithm being used:
        *   Fractal files with `type: phoenix` work well with `src/phoenix_fractal.py`
        *   Fractal files with `type: mandelbrot` work well with `src/mbrot_fractal.py`
        *   Don't get your hopes up for the other files; we'll come back to them in the next sprint
    *   This program creates PNG images as a side-effect
        *   Existing files are overwritten
        *   Make backups of these images *before* you change any code
        *   This will let you compare the program's output *before* and *after* your changes
    *   Read and run the unit tests
        *   See [Running Unit Tests.md](./4.0-Running_Unit_Tests.md) for instructions on running the tests
2.  Take the **Starter Code Quiz** on Canvas
    *   Do not worry if you can't answer all of the questions yet
    *   You can re-take the quiz as many times as you want before the project is due
3.  Fill out **Phase 0** in `doc/4.0-Plan.md`
    *   Each sprint gets its own SDP document
    *   Explain in your *own words* what the program does, how it does it, and what changes you expect to make
4.  Track your time in `doc/Signature.md`
5.  **Tag** the last commit in this phase `4.0-analyzed` and push it to GitLab.
    *   *Grace Points: if this tag is pushed before 11:59 PM on the Monday before the due date, you will receive up to 5 points back*


### Phase 1: Design (tag name `4.0-designed`)
*(30% of your effort)*

**Important - Unit Tests are the only Python code that is committed in this phase**

0.  You should be able to get 100% on the **Starter Code Quiz** by the end of this phase
1.  Write a first draft of `doc/Smells.md`
    *   You are required, at minimum, to identify one instance of each of the 10 code smells discussed in the lecture notes
    *   But you don't have to stop at 10 - there are plenty of problems with this code!
    *   The [GitLab Markdown Guide](https://gitlab.cs.usu.edu/help/user/markdown.md) will help you write an attractive document
2.  Write a first draft of the **User's Manual** in the file `doc/Manual.md`
    *   This file describes the existing user interface (UI) and explains how to correctly use the software
    *   Include a list of fractal files in `data/` that are compatible with this program
    *   You may use AI tools such as ChatGPT or GitHub Copilot to assist you
        *   If you do this, explain how you used it in your Software Development Plan
        *   Clearly identify the text that was written by the tool
    *   Remember to describe the outward interface of the program, and to abstain from explaining its inner workings!
3.  Write the first draft of unit tests
    *   Practice Test-Driven Development: at this point in the project these tests will not pass because the code they test hasn't yet been written
        *   You may use AI tools such as ChatGPT or GitHub Copilot to assist you designing unit tests
        *   If you do this, explain how you used it in your Software Development Plan
        *   Clearly identify any source code that was written by the tool
    *   These tests are a design tool that help you plan what these classes will do
    *   You may need to update these tests as you find and fix problems with your program (or the tests themselves!)
4.  Fill out **Phase 1** in `doc/4.0-Plan.md`
    *   This will be the longest portion of the document
    *   **Include pseudocode for the Phoenix and Mandelbrot algorithms**
        *   You may use AI tools such as ChatGPT or GitHub Copilot to assist you in writing pseudocode
        *   If you do this, explain how you used it in your Software Development Plan
        *   Clearly identify the pseudocode that was written by the tool
5.  Track your time in `doc/Signature.md`
6.  **Tag** the last commit in this phase `4.0-designed` and push it to GitLab.
    *   *Grace Points: if this tag is pushed before 11:59 PM on the Monday before the due date, you will receive up to 5 points back*


### Phase 2: Implementation (tag name `4.0-implemented`)
*(15% of your effort)*

**Finally, you can write code!**

0.  In this phase you will re-write the source code.
    *   The starter code is re-distributed into the modules named in [4.0-Project_Requirements.md](./4.0-Project_Requirements.md).
    *   **Do not** move on if your program crashes unexpectedly!
    *   Follow these instructions to ensure that your refactoring efforts have not changed the *outward* behavior of the program:[Test To Ensure Quality](./4.0-Project_Requirements.md#test-to-ensure-quality)
1.  Update the **unit tests** to match your implementation.
    *   Tests will change as you find and fix problems with your program (or the tests themselves!)
    *   See [Running Unit Tests.md](./4.0-Running_Unit_Tests.md) for instructions on running the tests.
2.  By now `doc/Smells.md` contains at least **one** example of each kind of code smell found in the starter code.
3.  Fill out **Phase 2** in `doc/4.0-Plan.md`.
    *   As you work in this phase you may choose to deviate from the design you settled upon in the previous phase.  This is normal!
    *   Briefly explain what changed.
    *   Do not paste long passages of Python code in your plan.
    *   Your write-up for this phase may be very short.
4.  Track your time in `doc/Signature.md`.
5.  **Tag** the last commit in this phase `4.0-implemented` and push it to GitLab.


### Phase 3: Testing and Debugging (tag name `4.0-tested`)
*(30% of your effort)*

Your grade depends on how your program performs when run from the command line.  We don't use PyCharm to grade, so ensure your program runs correctly from the shell.

0.  All of your **unit tests** should pass by the end of this phase.
    *   See [Running Unit Tests.md](./4.0-Running_Unit_Tests.md) for instructions on running the tests.
1.  The tests in `src/tests/test_assertions.py` are given as examples, and should not be part of your final submission.
    *   Edit `src/run_tests.py` so that these example tests **will not run** for your grader.
2.  Fill out **Phase 3** in `doc/4.0-Plan.md`.
    *   Describe the tests cases you ran, both automated unit tests as well as your own manual test cases.
    *   Make note of the commands that you ran and what happened in the program.
3.  If you found bugs in this phase, explain what was wrong and how you fixed it.
4.  Track your time in `doc/Signature.md`.
5.  **Tag** the last commit in this phase `4.0-tested` and push it to GitLab.


### Phase 4: Deployment (tag name `4.0-deployed`)
*(5% of your effort)*

It is your responsibility to ensure that your program will work on your grader's computer.

*   Code that crashes and *cannot* be quickly fixed by the grader will receive **0 points** on the relevant portions of the rubric
*   Code that crashes but *can* be quickly fixed by the grader (or crashes only *some* of the time) will receive, at most, **half-credit** on the relevant portions of the rubric

The following procedure is the best way for you to know what it will be like when the grader runs your code:

0.  Review [How to Submit this Project](./How_To_Submit.md) and make sure that your submission is correct.
1.  Update your **User's manual** to match your implementation.
    *   Be sure to describe any error messages the user may see and explain how to get past them.
2.  Make a final draft of `doc/Smells.md`, if needed.
3.  **Tag** the last commit in this phase `4.0-deployed` and push it to GitLab.
4.  Push your code to GitLab, then check that all of your files, commits and **tags** appear there.
5.  Clone your project into a *different directory*, and re-run your test cases.
    *   Run `git log` and verify that all tags are present and on the correct commit.


### Phase 5: Maintenance (tag name `4.0-finished`)

0.  Tag `4.0-finished` on the commit that you want us to grade for this sprint.
    *   This tag lets you continue to work on the next sprint without the grader marking your submission late.
    *   Push this tag to GitLab.
1.  Review your `doc/4.0-Plan.md` and Signature.md one last time.
2.  Fill out **Phase 5** in `doc/4.0-Plan.md` by answering the questions.
3.  Make one final commit and push your **completed** Software Development Plan and Signature to GitLab.
4.  Make sure that you are happy with your **Starter Code Quiz** score.
5.  Respond to the **Project Reflection Survey** on Canvas.


## What We Look for When Grading

**Total points: 110**

*   **Repository Structure (10 points)**
    *   The repository is a clone of the starter code
    *   The repository's GitLab URL follows the naming convention
    *   All required files and directories are in their expected locations
    *   `.gitignore` is correct and no forbidden files or directories are present
    *   Each of these tags are present in your repository and are placed on the right commits:
        1.  `4.0-analyzed`
        2.  `4.0-designed`
        3.  `4.0-implemented`
        4.  `4.0-tested` (may be on the same commit as `4.0-implemented`)
        5.  `4.0-deployed` (may be on the same commit as `4.0-tested`)
        6.  `4.0-finished` (may be on the same commit as `4.0-deployed`)
*   **Time management (5 points)**
    *   Signature.md contains accurate information about the time you spent on this project
        *   The time reported on the **TOTAL** entry is the sum of the daily entries
    *   The *TODO* message and the placeholder entries have been removed
*   **Quality Documentation (35 points)**
    *   4.0-Plan.md
        *   Each section is filled out with a convincing level of detail
        *   The design phase has pseudocode instead of real code that was copied from the source files
        *   You may use AI tools such as ChatGPT or GitHub Copilot to assist you (If you do this, explain how you used it in your SDP and clearly identify text that was written by the tool)
    *   Smells.md
        *   10 different code smells (one of each type) cataloged in `doc/Smells.md`
        *   Each piece of required information is included: location, code snippet, explanation and fix description
    *   Manual.md
        *   The manual accurately represents the project's user interface
        *   Written at an appropriate level of detail for an end-user
        *   You may use AI tools such as ChatGPT or GitHub Copilot to assist you (If you do this, explain how you used it in your SDP and clearly identify text that was written by the tool)
*   **Unit Tests (20 points)**
    *   Increase coverage of unit tests to at least ten (10) tests
    *   The example tests in `src/tests/test_assertions.py` are not run by `src/run_tests.py`
    *   All unit tests pass
    *   No trivial unit tests are present
    *   You may use AI tools such as ChatGPT or GitHub Copilot to assist designing unit tests (If you do this, explain how you used it in your SDP and clearly identify tests that were written by the tool)
*   **Code Quality (20 points)**
    *   Overall project requirements are met
    *   No code smells from the starter code are in the final product, nor are any other notable code smells added
    *   Functions are organized into the correct modules
    *   No useless, variables, constants or import statements are present
    *   The program *does not* import any modules **except**:
        *   `math`
        *   `sys`
        *   `time`
        *   `tkinter`
        *   `typing`
        *   `unittest`
        *   Modules in the starter code
        *   New modules you wrote on your own
        *   There were many extraneous modules imported by the original starter code. You may choose to use any of those modules **so long as they serve an actual purpose in your solution**
            *   Ex. you can use `itertools` to create complex iterators, `functools` to use higher order functions, but you *cannot* use `turtle` because it serves no purpose in this program
    *   No import statement fail due to misspelling or incorrect capitalization.
        *   **Windows users** make sure that the capitalization of file names on GitLab match your `import` statements!
    *   No imports involve the `src.` package; this is the result of a PyCharm misconfiguration
    *   `eval()` or similar functions are not used; use `int()`, `float()` or `complex()` to convert strings into numbers
    *   You may use AI tools such as ChatGPT or GitHub Copilot to assist you (If you do this, explain how you used it in your SDP and clearly identify code that was written by the tool)
*   **Program Behavior (20 points)**
    *   The original user interface is preserved
    *   Image files are saved in the current working directory
    *   No new features or capabilities are added to the refactored program
