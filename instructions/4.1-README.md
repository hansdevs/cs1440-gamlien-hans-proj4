# CS 1440 Project 4.1: Object-Oriented Design - Instructions

Previous Semester Statistics     | Fall 2023 | Spring 2024 | Fall 2024
--------------------------------:|:---------:|:------------|:------------
Average Hours Spent              | 13.83     | 7.035       | 11.0
Standard Deviation Hours         | 7.75      | 6.566       | 5.57
% students thought this was Easy | 4.3%      | 2.9%        | 14.7%
... Medium                       | 35.9%     | 27.1%       | 33.8%
... Hard                         | 38.0%     | 20.0%       | 27.9%
... Too Hard/Did not complete    | 18.5%     | 50.0%       | 23.5%


**Grace Points**: If these tags are pushed to GitLab before 11:59 PM on the Monday before the due date, you will get up to **5 grace points** per tag:

0.  `4.1-analyzed`
1.  `4.1-designed`

To be eligible for grace points these tags must be on **separate commits**; they cannot be together.


*   [AI Tools / External Resources Policy](#ai-tools-external-resources-policy)
*   [Using Erik's Starter Code For This Sprint](#using-eriks-starter-code-for-this-sprint)
*   [How to Do This Project](#how-to-do-this-project)
    *   [Phase 0: Requirements Analysis](#phase-0-requirements-analysis-tag-name-41-analyzed)
    *   [Phase 1: Design](#phase-1-design-tag-name-41-designed)
    *   [Phase 2: Implementation](#phase-2-implementation-tag-name-41-implemented)
    *   [Phase 3: Testing and Debugging](#phase-3-testing-and-debugging-tag-name-41-tested)
    *   [Phase 4: Deployment](#phase-4-deployment-tag-name-41-deployed)
    *   [Phase 5: Maintenance](#phase-5-maintenance)
*   [What We Look for When Grading](#what-we-look-for-when-grading)



## AI Tools / External Resources Policy

I will not accept code or documentation that is not 100% your own creation.

You may use AI and external resources in ways that assist your understanding without replacing your effort or responsibility to learn.

Acceptable uses include:

*   Analyzing project instructions.
*   Understanding why and how starter code works.
*   Brainstorming ideas for a prototype.
*   Researching and explaining error messages.
*   Proofreading your documentation.

Unacceptable uses include:

*   Generating code, including unit tests.
*   Debugging your code or suggesting fixes.
*   Writing parts of your software plan or any other deliverable.

If you're stuck, ask for help before resorting to shortcuts or risking a violation.



## Using Erik's Starter Code For This Sprint

This project continues from where you left off in the last project.  If you are happy with your work on the last project, you may skip these instructions.

If did not complete Project 4.0 or are not satisfied with your code, you may use my solution as your starting point.

My solution is in my repository on GitLab in a branch called `erik-starter` under a directory called `erik-src/`.

When you followed my instructions to clone your repository, you kept a remote named `old-origin` that points to my repository on GitLab.  If you don't have the `old-origin` remote, run this command to add it:

```bash
$ git remote add old-origin https://gitlab.cs.usu.edu/duckiecorp/cs1440-falor-erik-proj4
```

Now use `git fetch` to download the new branch, and merge it into your own `master` branch:

```bash
$ git checkout master
$ git fetch old-origin
$ git merge --no-edit old-origin/erik-starter
```

(The `--no-edit` argument prevents Git from dumping you into a text editor to review a boring boilerplate commit message).

Finally, back up your `src/` directory and rename `erik-src/` to `src/`:

```bash
$ mv src my-src
$ mv erik-src src
$ git add .
$ git commit -m "Starting afresh with Erik's starter code"
```


## How to Do This Project

*   This is the second sprint of this project
    *   Turn in your work in the **same repository** as the last project
    *   Do not remove or change tags submitted in the first sprint
*   Late submissions are **not accepted**
    *   The 48-hour late policy **does not apply**
*   Your grade on this project depends upon how well you follow the SDP.  You demonstrate this by following instructions, writing clear documentation, and by *tagging* commits.
    *   Incorrectly spelled/capitalized tags are ignored.
    *   **If you tag a wrong commit**, or **incorrectly spell a tag** refer to `Using_Git/Intermediate_Git.md` in the lecture notes for instructions.


### Phase 0: Requirements Analysis (tag name `4.1-analyzed`)
*(20% of your effort)*

**Important - do not change any code in this phase**

0.  Read the [Project Requirements](./4.1-Project_Requirements.md) to orient yourself with the project
1.  Take the **Starter Code Quiz** on Canvas
    *   Do not worry if you can't answer all of the questions yet
    *   You can re-take the quiz as many times as you want before the project is due
2.  Fill out **Phase 0** in `doc/4.1-Plan.md`
    *   Each sprint gets its own SDP document
    *   Explain in your *own words* what the program does, how it does it, and what changes you expect to make
3.  Track your time in `doc/Signature.md`
4.  **Tag** the last commit in this phase `4.1-analyzed`
    *   *Grace Points: if this tag is pushed before 11:59 PM on the Monday before the due date, you will receive up to 5 points back*


### Phase 1: Design (tag name `4.1-designed`)
*(30% of your effort)*

**Important - Unit Tests are the only Python code that is committed in this phase**

0.  You should be able to get 100% on the **Starter Code Quiz** by the end of this phase
1.  Write a new draft of the **User's Manual** that describes the new UI
2.  New drafts of unit tests
    *   Practice Test-Driven Development: at this point in the project these tests will not pass because the code they test hasn't yet been written
        *   You may use AI tools such as ChatGPT or GitHub Copilot to assist you in designing unit tests
        *   If you do this, explain how you used it in your Software Development Plan
        *   Clearly identify any source code that was written by the tool
    *   These tests are a design tool that help you plan what these classes will do
    *   You may need to update these tests as you find and fix problems with your program (or the tests themselves!)
3.  Fill out **Phase 1** in `doc/4.1-Plan.md`
    *   This will be the longest portion of the document
    *   You may use AI tools such as ChatGPT or GitHub Copilot to assist you in writing pseudocode
        *   If you do this, explain how you used it in your Software Development Plan
        *   Clearly identify the pseudocode that was written by the tool
4.  Track your time in `doc/Signature.md`
5.  **Tag** the last commit in this phase `4.1-designed`
    *   *Grace Points: if this tag is pushed before 11:59 PM on the Monday before the due date, you will receive up to 5 points back*


### Phase 2: Implementation (tag name `4.1-implemented`)
*(15% of your effort)*

**Finally, you can write code!**

0.  By the end of this phase the program is runnable
    *   **Do not** move on if your program crashes unexpectedly!
    *   Don't forget to **close all files** your program uses
1.  Update the **unit tests** to match your implementation
    *   Tests will change as you find and fix problems with your program (or the tests themselves!)
    *   See [Running Unit Tests.md](./4.0-Running_Unit_Tests.md) for instructions on running the tests
2.  Update your **User's manual** to match your implementation
    *   Be sure to describe any error messages the user may see and explain how to get past them
3.  Fill out **Phase 2** in `doc/4.1-Plan.md`
    *   As you work in this phase you may choose to deviate from the design you settled upon in the previous phase.  This is normal!
    *   Briefly explain what changed
    *   Do not paste long passages of Python code in `doc/4.1-Plan.md`
    *   Your write-up for this phase may be very short
4.  Track your time in `doc/Signature.md`
5.  **Tag** the last commit in this phase `4.1-implemented`


### Phase 3: Testing and Debugging (tag name `4.1-tested`)
*(30% of your effort)*

Your grade depends on how your program performs when run from the command line.  We don't use PyCharm to grade, so ensure your program runs correctly from the shell.

0.  All of your **unit tests** should pass by the end of this phase
    *   See [Running Unit Tests.md](./4.0-Running_Unit_Tests.md) for instructions on running the tests
1.  Fill out **Phase 3** in `doc/4.1-Plan.md`
    *   Describe the tests cases you ran, both automated unit tests as well as your own manual test cases
    *   Make note of the commands that you ran and what happened in the program
2.  If you found bugs in this phase, explain what was wrong and how you fixed it
3.  Track your time in `doc/Signature.md`
4.  **Tag** the last commit in this phase `4.1-tested`


### Phase 4: Deployment (tag name `4.1-deployed`)
*(5% of your effort)*

It is your responsibility to ensure that your program will work on your grader's computer.

*   Code that crashes and *cannot* be quickly fixed by the grader will receive **0 points** on the relevant portions of the rubric
*   Code that crashes but *can* be quickly fixed by the grader (or crashes only *some* of the time) will receive, at most, **half-credit** on the relevant portions of the rubric

The following procedure is the best way for you to know what it will be like when the grader runs your code:

0.  Review [How to Submit this Project](./How_To_Submit.md) and make sure that your submission is correct
1.  Push your code to GitLab, then check that all of your files, commits and **tags** appear there
2.  Clone your project into a *different directory*, and re-run your test cases
    *   Run `git log` and verify that all tags are present and on the correct commit


### Phase 5: Maintenance

0.  **OPTIONAL** You *may* tag `4.1-finished` on the commit that you want us to grade for this sprint
    *   This tag isn't required because you will not need to work in this repository any more
1.  Review `doc/4.1-Plan.md` and `doc/Signature.md` one last time
2.  Fill out **Phase 5** in `doc/4.1-Plan.md` by answering the questions
3.  Make one final commit and push your **completed** Software Development Plan and Signature to GitLab
4.  Make sure that you are happy with your **Starter Code Quiz** score
5.  Respond to the **Project Reflection Survey** on Canvas



## What We Look for When Grading

**Total points: 110**

*   **Repository Structure (10 points)**
    *   The repository is a clone of the starter code
    *   The repository's GitLab URL follows the naming convention
    *   All required files and directories are in their expected locations
    *   `.gitignore` is correct and no forbidden files or directories are present
    *   Each of these tags are present in your repository and are placed on the right commits:
        1.  `4.1-analyzed`
        2.  `4.1-designed`
        3.  `4.1-implemented`
        4.  `4.1-tested` (may be on the same commit as `4.1-implemented`)
        5.  `4.1-deployed` (may be on the same commit as `4.1-tested`)
*   **Time management (5 points)**
    *   Signature.md contains accurate information about the time you spent on this project
        *   The time reported on the **TOTAL** entry is the sum of the daily entries
    *   The *TODO* message and the placeholder entries have been removed
*   **Quality Documentation (35 points)**
    *   4.1-Plan.md
        *   Each section is filled out with a convincing level of detail
        *   The design phase has pseudocode instead of real code that was copied from the source files
        *   You may use AI tools such as ChatGPT or GitHub Copilot to assist you (If you do this, explain how you used it in your SDP and clearly identify text that was written by the tool)
    *   Manual.md
        *   Written at an appropriate level of detail for an end-user
        *   You may use AI tools such as ChatGPT or GitHub Copilot to assist you (If you do this, explain how you used it in your SDP and clearly identify text that was written by the tool)
        *   Lists which **fractal algorithms** are implemented in this program
        *   Lists which **color palettes** may be given on the command line
*   **Unit Tests (20 points)**
    *   No fewer than ten (10) tests are present
    *   All unit tests pass
    *   No trivial unit tests are present
    *   You may use AI tools such as ChatGPT or GitHub Copilot to assist designing unit tests (If you do this, explain how you used it in your SDP and clearly identify tests that were written by the tool)
*   **Code Quality (20 points)**
    *   Overall project requirements are met
    *   Design Patterns Correctly Employed
        *   Factory Method and Strategy design patterns are employed effectively
        *   Default objects are produced by factories as appropriate
        *   Concrete and Abstract classes are used correctly
    *   The program *does not* import any modules **except**:
        *   Modules in the starter code
        *   `abc`
        *   `colour`
        *   `math`
        *   `pathlib`
        *   `sys`
        *   `time`
        *   `tkinter`
        *   `typing`
        *   `unittest`
        *   New modules you wrote on your own
        *   There were many extraneous modules imported by the original starter code. You may choose to use any of those modules **so long as they serve an actual purpose in your solution**
            *   Ex.: you can use `itertools` to create complex iterators, `functools` to use higher order functions, but you *cannot* use `turtle` because it serves no purpose in this program
    *   No import statement fail due to misspelling or incorrect capitalization.
        *   **Windows users** make sure that the capitalization of file names on GitLab match your `import` statements!
    *   No imports involve the `src.` package; this is the result of a PyCharm misconfiguration
    *   `eval()` or similar functions are not used; use `int()`, `float()` or `complex()` to convert strings into numbers
    *   You may use AI tools such as ChatGPT or GitHub Copilot to assist you (If you do this, explain how you used it in your SDP and clearly identify code that was written by the tool)
*   **Program Behavior (20 points)**
    *   When run with no arguments, a default fractal object and palette are used
        *   the default fractal meets size and color requirements (is not so large or has so many colors that it runs slowly)
    *   When run with one argument, the fractal file named by the user and the default palette are used
    *   When run with two arguments, the fractal file and palette named by the user are used
    *   Error messages are appropriate and informative
    *   Program's external behavior is as required
    *   Program runs when launched from *any* directory
    *   Program finishes in a reasonable amount of time
